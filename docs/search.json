[
  {
    "objectID": "Research/Research.html",
    "href": "Research/Research.html",
    "title": "Research",
    "section": "",
    "text": "My research results are constantly being updated here",
    "crumbs": [
      "Research"
    ]
  },
  {
    "objectID": "Publications/Publications.html",
    "href": "Publications/Publications.html",
    "title": "List of publications",
    "section": "",
    "text": "This page contains materials related to projects",
    "crumbs": [
      "Publications",
      "List of publications"
    ]
  },
  {
    "objectID": "Simulations/Neuron/Neuron.html",
    "href": "Simulations/Neuron/Neuron.html",
    "title": "NEURON simulator",
    "section": "",
    "text": "NEURON simulator excels at simulating complex, multi-compartmental models with detailed biophysics. The NEURON simulator is widely used in the simulation of detailed neural mechanisms and networks of neurons in the neuroscience literature. The original programming language used to code the NEURON is Higher Order Calculator (HOC). NEURON may also be programmed in Python, which we will explore more in this series of writings.",
    "crumbs": [
      "Neuron",
      "Overview"
    ]
  },
  {
    "objectID": "Simulations/Neuron/Fundamentals.html",
    "href": "Simulations/Neuron/Fundamentals.html",
    "title": "Fundamentals",
    "section": "",
    "text": "A few fundamentals would help the beginners aiming to use the NEURON simulator via python interface.\n\n\nParmeters: L - L is the length of the entire section in microns),\nnseg - (L/nseg)\ndiam -\nRa (Axial resistivity in ohm-cm -\nconnectivity -\nSection vs segment",
    "crumbs": [
      "Neuron",
      "Fundamentals"
    ]
  },
  {
    "objectID": "Simulations/Python/Python.html",
    "href": "Simulations/Python/Python.html",
    "title": "Python codes",
    "section": "",
    "text": "Python codes",
    "crumbs": [
      "Python",
      "Python codes"
    ]
  },
  {
    "objectID": "Tutorials/EstimationTheory/CramerRaoBound.html",
    "href": "Tutorials/EstimationTheory/CramerRaoBound.html",
    "title": "Cramer-Rao Lower Bound (CRLB)",
    "section": "",
    "text": "Cramer-Rao Lower Bound (CRLB)",
    "crumbs": [
      "Tutorials",
      "Estimation Theory",
      "Estimation Theory"
    ]
  },
  {
    "objectID": "Tutorials/Tutorials.html",
    "href": "Tutorials/Tutorials.html",
    "title": "List of tutorials here",
    "section": "",
    "text": "List of tutorials here",
    "crumbs": [
      "Tutorials"
    ]
  },
  {
    "objectID": "Tutorials/RandomProcess/MA.html",
    "href": "Tutorials/RandomProcess/MA.html",
    "title": "Moving Average (MA) process",
    "section": "",
    "text": "Moving Average (MA) process",
    "crumbs": [
      "Tutorials",
      "Random Processes",
      "MA"
    ]
  },
  {
    "objectID": "Tutorials/RandomProcess/ARMA.html",
    "href": "Tutorials/RandomProcess/ARMA.html",
    "title": "Auto-regressive moving average (ARMA) processess",
    "section": "",
    "text": "Auto-regressive moving average (ARMA) processess\nLet x(n) and v(n) are stationary random processes. If they are related by the linear constant coefficient differential equations\n\nx(n) + \\sum_{l=1}^{p} a(l) x(n-l)  = \\sum_{l=0}^q b(l)v(n-l)\n\nthen x(n) is called an ARMA(p,q) process.\n\nAutocorrelation\nOn both sides, multiplying by x^*(n-k) and taking the expectation \\mathbb{E} leads to\n\n\\begin{split}\n\\mathbb{E}[x(n)x^*(n-k)] + \\sum_{l=1}^{p} a(l) \\mathbb{E}[x(n-l) x^*(n-k)] & = \\sum_{l=0}^q b(l)\\mathbb{E}[v(n-l)x^*(n-k)] \\\\\nr_x(k) + \\sum_{l=1}^{p} a(l) r_x(k-l) & = \\sum_{l=0}^q b(l)r_{vx}(k-l)\n\\end{split}\n\\tag{1}\nIn the present form, Equation 1 is not useful. It would be nice to relate the cross-correlation term r_{vx}(k) on the RHS of Equation 1 to the autocorrelation term r_x(k) by invoking the linear filter theory. Since\n\nx(n) = \\sum_{m={-\\infty}}^{\\infty} v(m) h^*(n-m)\n\n\n\\begin{split}\nr_{vx}(k) &= \\mathbb{E}[v(n)x^*(n-k)]  \\\\\n& =  \\sum_{m=-\\infty}^{\\infty} \\mathbb{E}[v(n)v^*(m)  h^*(n-m-k)] \\\\\n  & = \\sigma_v^2 h^*(-k)\n\\end{split}\n\nThe above simplification is due to the assumption that v(n) is white noise. Now,\n\nr_{vx}(k-l) =  \\sigma_v^2 h^*(l-k)  \n\\tag{2}\nSubstituting Equation 2 in to Equation 1\n\n\\begin{split}\nr_x(k) + \\sum_{l=1}^{p} a(l) r_x(k-l) & = \\sum_{l=0}^q b(l)r_{vx}(k-l) \\\\\n& = \\sigma_v^2\\sum_{l=0}^q b(l)  h^*(l-k) \\\\\n& = \\sigma_v^2\\sum_{l=0}^{q-k} b(l+k)  h^*(l)\n\\end{split}\n\nThe last step is due to the assumption of causal h(n).\nThe equation\n\nr_x(k) + \\sum_{l=1}^{p} a(l) r_x(k-l)  = \\sigma_v^2\\sum_{l=0}^{q-k} b(l+k)  h^*(l)\n\nis called Yule-Walker equation. Let the RHS be\n  \nC_q(k)  = \\sigma_v^2\\sum_{l=0}^{q-k} b(l+k)  h^*(l)  \n\n\nr_x(k) + \\sum_{l=1}^{p} a(l) r_x(k-l) =\\left\\{ \\begin{array}{ c l }\n     C_q(k) & k  \\leq q \\\\\n    0                 &   k &gt;q\n  \\end{array}\\right.\n\nThe above YW equations can be written (for k=p+q) as\n\n\\begin{split}\nr_x(0) +   a(1) r_x(-1)  + a(2) r_x(-2) + \\cdots + a(p) r_x(-p) &= C_q(0)\\\\\nr_x(1) +   a(1) r_x(0)  + a(2) r_x(-1) + \\cdots + a(p) r_x(-(p-1)) &= C_q(1)\\\\\n\\vdots ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \\\\\nr_x(q) +   a(1) r_x(q-1)  + a(2) r_x(q-2) + \\cdots + a(p) r_x(-(p-q)) &= C_q(q)\\\\\n---------------------------\\\\\nr_x(q+1) +   a(1) r_x(q)  + a(2) r_x(q-1) + \\cdots + a(p) r_x(-(p-(q+1)) &= 0\\\\\nr_x(q+2) +   a(1) r_x(q+1)  + a(2) r_x(q) + \\cdots + a(p) r_x(-(p-(q+2))) &= 0\\\\\n\\vdots ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \\\\\nr_x(q+p) +   a(1) r_x(q+p-1)  + a(2) r_x(q-1) + \\cdots + a(p) r_x(q) &= 0\\\\\n\\end{split}\n\nIn matrix form,\n\n\\begin{bmatrix}\nr_x(0) &     r_x(-1)  &   r_x(-2) & \\cdots &  r_x(-p)  \\\\\nr_x(1) &     r_x(0)  &    r_x(-1) &  \\cdots &  r_x(-(p-1)) \\\\  \n\\vdots &     \\ddots  &    \\ddots &  \\vdots &  \\vdots  \\\\   \nr_x(q) &    r_x(q-1)  &  r_x(q-2) & \\cdots & r_x(-(p-q)) \\\\\n---- &     ----   &    ----  &  ----  & ----   \\\\   \nr_x(q+1) &    r_x(q)  &  r_x(q-1) & \\cdots &   r_x(-(p-(q+1)) \\\\\nr_x(q+2) &  r_x(q+1)  & r_x(q) & \\cdots &   r_x(-(p-(q+2)))  \\\\\n\\vdots &     \\ddots  &    \\ddots &  \\vdots &  \\vdots  \\\\   \nr_x(q+p) &    r_x(q+p-1)  & r_x(q-1) & \\cdots &  r_x(q)  \n\\end{bmatrix}\n\\begin{bmatrix}  1 \\\\ a(1) \\\\ a(2)  \\\\ \\vdots \\\\ a(p) \\\\\n\\end{bmatrix}\n= \\sigma_v^2 \\begin{bmatrix}  C_q(0) \\\\ C_q(1) \\\\ C_q(2)  \\\\ \\vdots \\\\ C_q(q)\\\\ ---- \\\\ 0 \\\\ 0 \\\\ \\vdots \\\\ 0\n\\end{bmatrix}",
    "crumbs": [
      "Tutorials",
      "Random Processes",
      "ARMA"
    ]
  },
  {
    "objectID": "Tutorials/RandomProcess/RandomProcessIntro.html",
    "href": "Tutorials/RandomProcess/RandomProcessIntro.html",
    "title": "List of tutorials here",
    "section": "",
    "text": "List of tutorials here\nA special list of random processes we discuss in this tutorial are\n\nARMA\nAR\nMA\nHarmonic processes",
    "crumbs": [
      "Tutorials",
      "Random Processes",
      "Random Processes"
    ]
  },
  {
    "objectID": "Tutorials/RandomProcess/AR.html",
    "href": "Tutorials/RandomProcess/AR.html",
    "title": "Auto-regressive (AR) processes",
    "section": "",
    "text": "Auto-regressive (AR) processes",
    "crumbs": [
      "Tutorials",
      "Random Processes",
      "AR"
    ]
  },
  {
    "objectID": "Tutorials/EstimationTheory/PointEstimation.html",
    "href": "Tutorials/EstimationTheory/PointEstimation.html",
    "title": "Point Estimation",
    "section": "",
    "text": "Point Estimation",
    "crumbs": [
      "Tutorials",
      "Estimation Theory",
      "Estimation Theory"
    ]
  },
  {
    "objectID": "Tutorials/EstimationTheory/EstimationTheoryIntro.html",
    "href": "Tutorials/EstimationTheory/EstimationTheoryIntro.html",
    "title": "List of topics in estimation",
    "section": "",
    "text": "List of topics in estimation",
    "crumbs": [
      "Tutorials",
      "Estimation Theory",
      "Estimation Theory"
    ]
  },
  {
    "objectID": "Simulations/Brian2/Brian2.html",
    "href": "Simulations/Brian2/Brian2.html",
    "title": "Brian2",
    "section": "",
    "text": "Brian2\nBrian2 allows scientists to simulate spiking neural network models using simple and concise high-level descriptions. This makes it more accessible to researchers who may not have extensive programming experience.",
    "crumbs": [
      "Brian2",
      "Brian2"
    ]
  },
  {
    "objectID": "Simulations/Neuron/Introduction.html",
    "href": "Simulations/Neuron/Introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Recently, NEURON simulator has python interface, with excellent beginners tutorials.\n\nBall and stick 1: Basic cell\nLoad the necessary modules\n\nfrom neuron import h\nfrom neuron.units import ms, mV, µm \n\nimport matplotlib.pyplot as plt   # For plotting using matplotlib\n\n  \nh.load_file(\"stdrun.hoc\") #load the standard run library to give us high-level simulation control functions (e.g. running a simulation for a given period of time):\n\n1.0\n\n\nDefine one cell with soma and dendrite (with necessary parameters, morphology) using python class\n\nclass BallAndStick:\n    def __init__(self, gid):\n        self._gid = gid\n        self._setup_morphology()\n        self._setup_biophysics()\n\n    def _setup_morphology(self):\n        self.soma = h.Section(name=\"soma\", cell=self)\n        self.dend = h.Section(name=\"dend\", cell=self)\n        self.dend.connect(self.soma)\n        self.all = self.soma.wholetree()\n        self.soma.L = self.soma.diam = 12.6157 * µm\n        self.dend.L = 200 * µm\n        self.dend.diam = 1 * µm\n\n    def _setup_biophysics(self):\n        for sec in self.all:\n            sec.Ra = 100  # Axial resistance in Ohm * cm\n            sec.cm = 1  # Membrane capacitance in micro Farads / cm^2\n        self.soma.insert(\"hh\")\n        for seg in self.soma:\n            seg.hh.gnabar = 0.12  # Sodium conductance in S/cm2\n            seg.hh.gkbar = 0.036  # Potassium conductance in S/cm2\n            seg.hh.gl = 0.0003  # Leak conductance in S/cm2\n            seg.hh.el = -54.3 * mV  # Reversal potential \n        self.dend.insert(\"pas\")  # # Insert passive current in the dendrite  \n        for seg in self.dend:   \n            seg.pas.g = 0.001  # Passive conductance in S/cm2        \n            seg.pas.e = -65 * mV  # Leak reversal potential             \n\n    def __repr__(self):\n        return \"BallAndStick[{}]\".format(self._gid)\n\n\nmy_cell = BallAndStick(0)\n\n\n# Make sure soma is hh and dendtrite is passive membrane\nfor sec in h.allsec():\n    print(\"%s: %s\" % (sec, \", \".join(sec.psection()[\"density_mechs\"].keys())))\n\nBallAndStick[0].soma: hh\nBallAndStick[0].dend: pas\n\n\n\nStimulus\n\nstim = h.IClamp(my_cell.dend(1))  # at the origin of the dentrite\nstim.delay = 5 #ms\nstim.dur = 1 #ms\nstim.amp = 0.1  # nA\n\n\n\nRecording soma voltage\n\nsoma_v = h.Vector().record(my_cell.soma(0.5)._ref_v)\nt = h.Vector().record(h._ref_t)\n\n\n\nInitialization\n\nh.finitialize(-65 * mV) # initialize membrane potential \n\nh.continuerun(25 * ms) # run until time 25 ms:\n\n0.0\n\n\n\nplt.figure()\nplt.plot(t, soma_v)\nplt.xlabel(\"t (ms)\")\nplt.ylabel(\"v (mV)\")\nplt.show()",
    "crumbs": [
      "Neuron",
      "Introduction"
    ]
  },
  {
    "objectID": "Simulations/R/R.html",
    "href": "Simulations/R/R.html",
    "title": "R",
    "section": "",
    "text": "R\nA few R packages",
    "crumbs": [
      "R"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "I am a computational neuroscience enthusiast with signal processing expertise, currently studying about brain. A passionate explorer of computational neuroscience methods, my diverse interests span from analyzing neural signals (spikes/fMRI/EEG/DTI) to developing cutting-edge dynamic models for neuroscientific applications. If you would like to collaborate with my explorations, please contact me."
  },
  {
    "objectID": "index.html#current-research-interests",
    "href": "index.html#current-research-interests",
    "title": "Welcome!",
    "section": "Current Research Interests",
    "text": "Current Research Interests\n\nComputational Neuroscience\nSignal Processing\nStatistics and Probability"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Welcome!",
    "section": "Education",
    "text": "Education\nPhD in Signal Processing\nMasters in Communication Engineering\nBachelors in Electronics and Communication Engineering"
  },
  {
    "objectID": "Simulations/Neuron/Fundamentals.html#section",
    "href": "Simulations/Neuron/Fundamentals.html#section",
    "title": "Fundamentals",
    "section": "",
    "text": "Parmeters: L - L is the length of the entire section in microns),\nnseg - (L/nseg)\ndiam -\nRa (Axial resistivity in ohm-cm -\nconnectivity -\nSection vs segment",
    "crumbs": [
      "Neuron",
      "Fundamentals"
    ]
  },
  {
    "objectID": "Simulations/Neuron/Neuron.html#installation-of-neuron-with-gpu-support-coreneuron",
    "href": "Simulations/Neuron/Neuron.html#installation-of-neuron-with-gpu-support-coreneuron",
    "title": "NEURON simulator",
    "section": "Installation of NEURON with GPU support (CoreNEURON)",
    "text": "Installation of NEURON with GPU support (CoreNEURON)\n\n1. Clone the latest version of NEURON\ngit clone https://github.com/neuronsimulator/nrn\ncd nrn\n\n\n2. Build\nmkdir build\ncd build\n\n\n3. Load the modules\nmodule load intel openmpi python cmake nvidia-hpc-sdk cuda  \nIn normal Linux systems, the modules are in the path /usr/share/modules/modulefiles. If the directory does not exists, then install using\n\nsudo apt-get install environment-modules\n\n# and configure the ~/.bashrc with \nsource /etc/profile.d/modules.sh\n\n\n\n4. Compile\nFollowing compilation is for GPU architecture of 61\ncmake .. \\\n      -DNRN_ENABLE_CORENEURON=ON \\\n      -DCORENRN_ENABLE_GPU=ON \\\n      -DNRN_ENABLE_INTERVIEWS=OFF \\\n      -DNRN_ENABLE_RX3D=OFF \\\n      -DCMAKE_INSTALL_PREFIX=$HOME/install \\\n      -DCMAKE_C_COMPILER=nvc \\\n      -DCMAKE_CXX_COMPILER=nvc++ \\\n      -DCMAKE_PREFIX_PATH=/usr/lib/x86_64-linux-gnu \\\n      -DCMAKE_CUDA_ARCHITECTURES=\"61\" \\  # need to know this\n      -DCMAKE_EXE_LINKER_FLAGS: \"-cuda -gpu=cuda12.6,lineinfo,cc61 -acc\" # not necessary\n      -DCMAKE_CXX_FLAGS=\"-O3 -g\" \\\n      -DCMAKE_C_FLAGS=\"-O3 -g\" \\\n      -DCMAKE_BUILD_TYPE=Custom\nCheck the CUDA_ARCHITECTURES via (nvidia-smi; assuming it is installed)\nnvidia-smi --query-gpu=compute_cap --format=csv\n\n\n5. Ringtest\nBest way to check if the installation is working properly is by running the ring test as in\ngit clone https://github.com/nrnhines/ringtest.git\ncd ringtest\n\nnrnivmodl -coreneuron mod\n\n# in any NEURON code add the following lines for CoreNEURON support (python files only)\n\nh.cvode.cache_efficient(1)\nif use_coreneuron:\n    from neuron import coreneuron\n    coreneuron.enable = True\n    coreneuron.gpu = coreneuron_gpu\n    \n    \n#run the three performance test \n\n# NEURON CPU Run\nmpiexec -n 1 ./x86_64/special -mpi -python ringtest.py -tstop 10 -nring 128 -ncell 128 -branch 32 64\n\n# CoreNEURON CPU Run\nmpiexec -n 1 ./x86_64/special -mpi -python ringtest.py -tstop 10 -nring 128 -ncell 128 -branch 32 64 -coreneuron\n\n# CoreNEURON GPU Run\nmpiexec -n 1 ./x86_64/special -mpi -python ringtest.py -tstop 10 -nring 128 -ncell 128 -branch 32 64 -coreneuron -gpu",
    "crumbs": [
      "Neuron",
      "Overview"
    ]
  },
  {
    "objectID": "index.html#work-experience",
    "href": "index.html#work-experience",
    "title": "Welcome!",
    "section": "Work Experience",
    "text": "Work Experience"
  }
]